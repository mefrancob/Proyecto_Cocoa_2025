{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASIFICACIÓN DE CACAO POR ETAPAS DE MADURACIÓN**\n",
    "\n",
    "Este proyecto tiene como objetivo clasificar imágenes de cacao, de acuerdo a sus etapas de maduración. Se presentan en 4 diferentes etapas; la primera de cero-dos meses; la segunda de dos-cuatro meses; la tercera de cuatro-seis meses; la cuarta de seis meses en adelante. \n",
    "Esto cobra importancia en diversos sectores como la agricultura y la investigación. Dado que se pude tener un mayor control y una planeacipon de los cultivos de cacao y sirve para el estudio de los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvieron las imágenes del siguiente repositorio: https://doi.org/10.5281/zenodo.7968315, las imágenes están en formato COCO, el data set contiene 4116 imágenes, que se encuentran clasificadas en cinco tipos. Cada tipo de imagen se encuentra etiquetada, cada una de estas etiquetas en archivos independientes, de estos el tipo A no será utilizado en este proyecto, debido a que contiene imágenes no relevantes para el problema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se instalan librerías\n",
    "%pip install pycocotools \n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el data frame llamado df, el cual contiene la información de las imágenes. Posteriormente se divide en tres conjuntos; test, validación y entrenamiento. Se dividieron de la siguiente manera; Train: 2795 imágenes; Validación: 597 imágenes y Test: 597 imágenes. Se balancearon las imágenes para que cada clase contenga aproximadamente la misma cantidad, usando operaciones como rotación, translación, etc. Por último, el data frame queda conformado con la siguiente información: image_id (clave primaria), file_name (nombre del archivo), path (ruta), width y height (medidas), categories, class_name y class_number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_custom_dataset(base_path, folder_names):\n",
    "    \"\"\"\n",
    "    Carga datasets COCO desde la estructura específica de carpetas.\n",
    "    \n",
    "    Parameters:\n",
    "    base_path (str): Ruta base (RipSetCocoaCNCH12/RipSetCocoaCNCH12/COCO_10)\n",
    "    folder_names (list): Lista de nombres de carpetas (images_C1, images_C2, etc.)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame consolidado con toda la información\n",
    "    \"\"\"\n",
    "    all_image_data = []\n",
    "    \n",
    "    # Imprimir las rutas para debug\n",
    "    print(f\"Ruta base: {base_path}\")\n",
    "    print(\"Carpetas a procesar:\", folder_names)\n",
    "    \n",
    "    for folder_name in folder_names:\n",
    "        # Construir rutas\n",
    "        images_path = os.path.join(base_path, folder_name)\n",
    "        annotation_path = os.path.join(base_path, f'{folder_name}.json')\n",
    "        \n",
    "        print(f\"\\nProcesando carpeta: {folder_name}\")\n",
    "        print(f\"Ruta de imágenes: {images_path}\")\n",
    "        print(f\"Ruta de anotaciones: {annotation_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Verificar si el archivo JSON existe\n",
    "            if not os.path.exists(annotation_path):\n",
    "                print(f\"¡Advertencia! No se encontró el archivo: {annotation_path}\")\n",
    "                continue\n",
    "                \n",
    "            # Cargar archivo JSON\n",
    "            with open(annotation_path, 'r') as f:\n",
    "                coco_data = json.load(f)\n",
    "            \n",
    "            print(f\"JSON cargado exitosamente para {folder_name}\")\n",
    "            \n",
    "            # Crear diccionario de categorías\n",
    "            categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "            \n",
    "            # Crear diccionario de imágenes\n",
    "            images = {img['id']: img for img in coco_data['images']}\n",
    "            \n",
    "            # Organizar anotaciones por imagen\n",
    "            image_annotations = {}\n",
    "            for ann in coco_data['annotations']:\n",
    "                img_id = ann['image_id']\n",
    "                if img_id not in image_annotations:\n",
    "                    image_annotations[img_id] = set()\n",
    "                image_annotations[img_id].add(categories[ann['category_id']])\n",
    "            \n",
    "            # Obtener el número de clase del nombre de la carpeta\n",
    "            class_number = int(folder_name.split('_C')[1])\n",
    "            \n",
    "            # Preparar datos para el DataFrame\n",
    "            for img_id, annotations in image_annotations.items():\n",
    "                img_info = images[img_id]\n",
    "                image_entry = {\n",
    "                    'image_id': img_id,\n",
    "                    'file_name': img_info['file_name'],\n",
    "                    'path': os.path.join(images_path, img_info['file_name']),\n",
    "                    'width': img_info.get('width', None),\n",
    "                    'height': img_info.get('height', None),\n",
    "                    'categories': list(annotations),\n",
    "                    'class_name': folder_name,  # Guardamos el nombre de la carpeta\n",
    "                    'class_number': class_number  # Guardamos el número de clase\n",
    "                }\n",
    "                all_image_data.append(image_entry)\n",
    "            \n",
    "            print(f\"Procesadas {len(image_annotations)} imágenes de {folder_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {folder_name}: {str(e)}\")\n",
    "    \n",
    "    # Crear DataFrame consolidado\n",
    "    if not all_image_data:\n",
    "        raise ValueError(\"No se encontraron datos en ninguna carpeta\")\n",
    "    \n",
    "    df = pd.DataFrame(all_image_data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_test_split(df, val_size=0.15, test_size=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    Crea splits estratificados manteniendo la distribución de clases.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    train_data, val_data, test_data = [], [], []\n",
    "    \n",
    "    # Procesar por clase\n",
    "    for class_name in df['class_name'].unique():\n",
    "        class_data = df[df['class_name'] == class_name]\n",
    "        \n",
    "        # Calcular tamaños\n",
    "        n_samples = len(class_data)\n",
    "        n_test = int(n_samples * test_size)\n",
    "        n_val = int(n_samples * val_size)\n",
    "        \n",
    "        # Dividir los datos\n",
    "        shuffled = class_data.sample(frac=1, random_state=seed)\n",
    "        train_data.append(shuffled[:(n_samples-n_test-n_val)])\n",
    "        val_data.append(shuffled[(n_samples-n_test-n_val):(n_samples-n_test)])\n",
    "        test_data.append(shuffled[(n_samples-n_test):])\n",
    "    \n",
    "    # Combinar los datos\n",
    "    train_df = pd.concat(train_data).reset_index(drop=True)\n",
    "    val_df = pd.concat(val_data).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_data).reset_index(drop=True)\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def verify_dataset(df):\n",
    "    \"\"\"\n",
    "    Verifica la integridad del dataset.\n",
    "    \"\"\"\n",
    "    verification = {\n",
    "        'total_images': len(df),\n",
    "        'images_per_class': df['class_name'].value_counts().to_dict(),\n",
    "        'missing_images': [],\n",
    "        'categories_per_class': {}\n",
    "    }\n",
    "    \n",
    "    # Verificar que las imágenes existen\n",
    "    for idx, row in df.iterrows():\n",
    "        if not os.path.exists(row['path']):\n",
    "            verification['missing_images'].append(row['path'])\n",
    "    \n",
    "    # Analizar categorías por clase\n",
    "    for class_name in df['class_name'].unique():\n",
    "        class_data = df[df['class_name'] == class_name]\n",
    "        categories = [cat for cats in class_data['categories'] for cat in cats]\n",
    "        verification['categories_per_class'][class_name] = pd.Series(categories).value_counts().to_dict()\n",
    "    \n",
    "    return verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir las rutas\n",
    "ruta_1 = 'C:\\\\Users\\\\melis\\\\Desktop\\\\Proyecto_Cocoa\\\\RipSetCocoaCNCH12\\\\RipSetCocoaCNCH12\\\\COCO_10'\n",
    "ruta_2 = ['images_C1', 'images_C2', 'images_C3', 'images_C4']\n",
    "\n",
    "# 2. Cargar el dataset\n",
    "try:\n",
    "    df = load_custom_dataset(ruta_1, ruta_2)\n",
    "    \n",
    "    # 3. Verificar la integridad del dataset\n",
    "    verification = verify_dataset(df)\n",
    "    print(\"\\nEstadísticas del dataset:\")\n",
    "    print(f\"Total de imágenes: {verification['total_images']}\")\n",
    "    print(\"\\nImágenes por clase:\")\n",
    "    for class_name, count in verification['images_per_class'].items():\n",
    "        print(f\"{class_name}: {count}\")\n",
    "\n",
    "    if verification['missing_images']:\n",
    "        print(\"\\n¡Advertencia! Imágenes faltantes:\", len(verification['missing_images']))\n",
    "\n",
    "    # 4. Crear los splits\n",
    "    train_df, val_df, test_df = create_train_val_test_split(df)\n",
    "\n",
    "    # 5. Ver distribución final\n",
    "    print(\"\\nDistribución final:\")\n",
    "    print(f\"Train: {len(train_df)} imágenes\")\n",
    "    print(f\"Validación: {len(val_df)} imágenes\")\n",
    "    print(f\"Test: {len(test_df)} imágenes\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error en el proceso: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toman 10 imágenes de manera aleatoria y se fijan para posteriormente realizar muestras con ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Muestra aleatoria de 10 imágenes\n",
    "sample_images = train_df.sample(n=10, random_state=42)\n",
    "\n",
    "# Mostrar las imágenes seleccionadas\n",
    "plt.figure(figsize=(15, 10))  # Tamaño del lienzo\n",
    "\n",
    "for i, row in enumerate(sample_images.iterrows()):\n",
    "    img_path = row[1]['path']  # Ruta de la imagen\n",
    "    img = Image.open(img_path)  # Abrir la imagen\n",
    "    \n",
    "    plt.subplot(2, 5, i + 1)  # Crear subgráficos (2 filas, 5 columnas)\n",
    "    plt.imshow(img)  # Mostrar la imagen\n",
    "    plt.axis('off')  # Ocultar ejes\n",
    "    plt.title(row[1]['class_name'])  # Título con la categoría de la imagen\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se hacen exploraciones como canny, espacios de color (HSV, LAB y RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot(imagen_1, transform_func, transform_name=\"Transformación\", **kwargs):\n",
    "    \"\"\"\n",
    "    Muestra imágenes originales y procesadas con cualquier función de transformación.\n",
    "    \n",
    "    Args:\n",
    "    - imagen_1: DataFrame que contiene las rutas de las imágenes.\n",
    "    - transform_func: Función de transformación que se aplicará a cada imagen.\n",
    "                      Debe aceptar un parámetro (ruta de la imagen) y devolver la imagen transformada.\n",
    "    - transform_name: Nombre de la transformación, para usar en los títulos (por defecto, \"Transformación\").\n",
    "    - **kwargs: Argumentos adicionales que serán pasados a la función de transformación.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Visualización directa de las imágenes.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 50))  # Incrementar el tamaño del lienzo\n",
    "\n",
    "    for i, row in enumerate(imagen_1.iterrows()):\n",
    "        img_path = row[1]['path']  # Ruta de la imagen\n",
    "        \n",
    "        # Imagen original\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(10, 2, 2 * i + 1)  # Una fila por imagen, columna 1 para original\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Original', fontsize=16)\n",
    "        \n",
    "        # Imagen procesada\n",
    "        transformed_img = transform_func(img_path, **kwargs)\n",
    "        plt.subplot(10, 2, 2 * i + 2)\n",
    "        \n",
    "        if len(transformed_img.shape) == 2:  # Canal individual\n",
    "            color_space = kwargs.get('color_space', None)\n",
    "            channel = kwargs.get('channel', None)\n",
    "            \n",
    "            if color_space == \"HSV\" and channel in [1, 2]:\n",
    "                # Escalar canal S o V de HSV para visualizarlo como intensidad\n",
    "                color_image = cv2.cvtColor(transformed_img, cv2.COLOR_GRAY2RGB)\n",
    "                plt.imshow(color_image)\n",
    "            elif color_space == \"HSV\" and channel == 0:\n",
    "                # Canal Hue en colores\n",
    "                plt.imshow(transformed_img, cmap='hsv')\n",
    "            elif color_space == \"Lab\":\n",
    "                if channel == 0:\n",
    "                    # Canal L (Luminosidad) como escala de grises\n",
    "                    plt.imshow(transformed_img, cmap='gray')\n",
    "                elif channel == 1:\n",
    "                    # Canal a: verde a rojo\n",
    "                    plt.imshow(transformed_img, cmap=mcolors.LinearSegmentedColormap.from_list('green-red', ['green', 'gray', 'red']))\n",
    "                elif channel == 2:\n",
    "                    # Canal b: azul a amarillo\n",
    "                    plt.imshow(transformed_img, cmap=mcolors.LinearSegmentedColormap.from_list('blue-yellow', ['blue', 'gray', 'yellow']))\n",
    "            else:\n",
    "                # Escala de grises por defecto\n",
    "                plt.imshow(transformed_img, cmap='gray')\n",
    "        else:  # Imagen completa (RGB o similar)\n",
    "            plt.imshow(transformed_img)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.title(transform_name, fontsize=16)\n",
    "\n",
    "    plt.tight_layout(pad=5.0)  # Aumentar el espacio entre las imágenes\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def apply_canny_edge_detection(image_path, threshold1=50, threshold2=100):\n",
    "    \"\"\"\n",
    "    Aplica la detección de bordes tipo Canny a una imagen.\n",
    "    \n",
    "    Args:\n",
    "    - image_path: Ruta de la imagen.\n",
    "    - threshold1: Umbral inferior para la detección de bordes.\n",
    "    - threshold2: Umbral superior para la detección de bordes.\n",
    "    \n",
    "    Returns:\n",
    "    - edge_image: Imagen con los bordes detectados.\n",
    "    \"\"\"\n",
    "    # Cargar la imagen en escala de grises\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Aplicar la detección de bordes\n",
    "    edges = cv2.Canny(img, threshold1, threshold2)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "muestra=train_df.sample(n=10, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "plot(muestra,apply_canny_edge_detection,\"canny\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_color_space(image_path, color_space=\"RGB\", channel=None):\n",
    "    \"\"\"\n",
    "    Transforma la imagen a un espacio de color específico y permite extraer un canal.\n",
    "    \n",
    "    Args:\n",
    "    - image_path: Ruta de la imagen.\n",
    "    - color_space: Espacio de color al que se transformará la imagen.\n",
    "                   Valores soportados: \"RGB\", \"HSV\", \"Lab\", \"BGR\".\n",
    "    - channel: Canal específico a extraer (0, 1, 2). Por ejemplo, \"0\" para el canal L en Lab.\n",
    "    \n",
    "    Returns:\n",
    "    - transformed_img: Imagen transformada o canal específico.\n",
    "    \"\"\"\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Transformar al espacio de color especificado\n",
    "    if color_space == \"RGB\":\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    elif color_space == \"GRAY\":\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    elif color_space == \"HSV\":\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    elif color_space == \"Lab\":\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "    elif color_space == \"BGR\":\n",
    "        pass  # Sin cambios\n",
    "    else:\n",
    "        raise ValueError(f\"Espacio de color '{color_space}' no soportado.\")\n",
    "    \n",
    "    # Extraer un canal específico si se indica\n",
    "    if channel is not None:\n",
    "        if len(img.shape) == 3:  # Asegurarse de que la imagen tiene canales\n",
    "            img = img[:, :, channel]\n",
    "        else:\n",
    "            raise ValueError(f\"La imagen no tiene canales disponibles para extraer.\")\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra_1=muestra\n",
    "\n",
    "plot(\n",
    "    imagen_1=muestra_1,\n",
    "    transform_func=transform_color_space,\n",
    "    transform_name=\"Espacio de color HSV\",\n",
    "    color_space=\"HSV\",\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra_2=muestra\n",
    "\n",
    "\n",
    "\n",
    "plot(\n",
    "    imagen_1=muestra_2,\n",
    "    transform_func=transform_color_space,\n",
    "    transform_name=\"Espacio de color LAB\",\n",
    "    color_space=\"Lab\"\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra_3=muestra\n",
    "plot(\n",
    "    imagen_1=muestra_3,\n",
    "    transform_func=transform_color_space,\n",
    "    transform_name=\"Espacio de color RGB\",\n",
    "    color_space=\"RGB\"\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presentan los histogramas de las imágenes originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram(muestra, transform_func=None, color_space=\"RGB\", **kwargs):\n",
    "    \"\"\"\n",
    "    Muestra los histogramas de las imágenes en la muestra.\n",
    "    \n",
    "    Args:\n",
    "    - muestra: DataFrame con las rutas de las imágenes.\n",
    "    - transform_func: Función de transformación para cambiar el espacio de color (opcional).\n",
    "                      Si None, se analiza el espacio de color original.\n",
    "    - color_space: Espacio de color para las imágenes (por defecto, \"RGB\").\n",
    "                   Otros valores: \"GRAY\", \"HSV\", \"Lab\".\n",
    "    - **kwargs: Argumentos adicionales que serán pasados a la función de transformación.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Visualización directa de los histogramas.\n",
    "    \"\"\"\n",
    "    for i, row in enumerate(muestra.iterrows()):\n",
    "        img_path = row[1]['path']  # Ruta de la imagen\n",
    "        img = cv2.imread(img_path)  # Leer imagen en BGR\n",
    "        \n",
    "        # Transformar espacio de color si se especifica\n",
    "        if transform_func:\n",
    "            img = transform_func(img_path, **kwargs)\n",
    "        \n",
    "        # Espacios de color\n",
    "        if color_space == \"RGB\":\n",
    "            channels = ['Red', 'Green', 'Blue']\n",
    "            colors = ['r', 'g', 'b']\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        elif color_space == \"HSV\":\n",
    "            channels = ['Hue', 'Saturation', 'Value']\n",
    "            colors = ['m', 'c', 'y']\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space == \"Lab\":\n",
    "            channels = ['L', 'a', 'b']\n",
    "            colors = ['gray', 'g', 'b']\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "        elif color_space == \"GRAY\":\n",
    "            channels = ['Gray']\n",
    "            colors = ['k']\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            raise ValueError(f\"Espacio de color '{color_space}' no soportado.\")\n",
    "        \n",
    "        # Mostrar histogramas\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(f\"Histogram for Image {i+1}\")\n",
    "        \n",
    "        if len(img.shape) == 2:  # Escala de grises\n",
    "            hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "            plt.plot(hist, color='k', label='Gray')\n",
    "        else:  # Canales de color\n",
    "            for j, (channel, color) in enumerate(zip(channels, colors)):\n",
    "                hist = cv2.calcHist([img], [j], None, [256], [0, 256])\n",
    "                plt.plot(hist, color=color, label=channel)\n",
    "        \n",
    "        plt.xlabel(\"Intensity Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(\n",
    "    muestra=muestra\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica un filtro de suavisado gaussiano y CLAHE a las imágenes, obteniendo buenos resultados en la calidad de estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image_to_display(image_path, clip_limit=2.0, tile_grid_size=(8, 8), kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Aplica un filtro de suavizado gaussiano y CLAHE a una imagen y la devuelve para visualización.\n",
    "    \n",
    "    Args:\n",
    "    - image_path: Ruta de la imagen de entrada.\n",
    "    - clip_limit: Parámetro de contraste para CLAHE.\n",
    "    - tile_grid_size: Tamaño de las regiones para CLAHE.\n",
    "    - kernel_size: Tamaño del kernel para el filtro gaussiano.\n",
    "    \n",
    "    Returns:\n",
    "    - processed_img: Imagen procesada.\n",
    "    \"\"\"\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Aplicar filtro de suavizado gaussiano\n",
    "    blurred_img = cv2.GaussianBlur(img, kernel_size, 0)\n",
    "    \n",
    "    # Convertir a Lab para aplicar CLAHE\n",
    "    lab = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2Lab)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Aplicar CLAHE al canal L\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Reconstruir la imagen Lab y convertir a BGR\n",
    "    lab = cv2.merge((cl, a, b))\n",
    "    processed_img = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)\n",
    "    \n",
    "    return processed_img\n",
    "\n",
    "\n",
    "def display_processed_images(df, path_column='path', clip_limit=2.0, tile_grid_size=(8, 8), kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Procesa un conjunto de imágenes desde un DataFrame y las muestra en pantalla.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame con las rutas de las imágenes.\n",
    "    - path_column: Nombre de la columna en el DataFrame que contiene las rutas de las imágenes.\n",
    "    - clip_limit: Parámetro de contraste para CLAHE.\n",
    "    - tile_grid_size: Tamaño de las regiones para CLAHE.\n",
    "    - kernel_size: Tamaño del kernel para el filtro gaussiano.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        \n",
    "        # Leer y procesar la imagen\n",
    "        original_img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)  # Convertir a RGB para matplotlib\n",
    "        processed_img = preprocess_image_to_display(\n",
    "            image_path,\n",
    "            clip_limit=clip_limit,\n",
    "            tile_grid_size=tile_grid_size,\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "        processed_img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)  # Convertir a RGB para matplotlib\n",
    "        \n",
    "        # Mostrar la imagen original y la procesada\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Imagen original\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Imagen procesada\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(processed_img)\n",
    "        plt.title(\"Procesada (Suavizado + CLAHE)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_processed_images(\n",
    "    df=muestra,\n",
    "    path_column='path',  # Cambia si tu columna tiene otro nombre.\n",
    "    clip_limit=2.0, \n",
    "    tile_grid_size=(8, 8), \n",
    "    kernel_size=(5, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una comparación de la imagen original con su histograma y de la imagen procesada también con su respectivo histograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image_with_histogram(image_path, clip_limit=2.0, tile_grid_size=(8, 8), kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Aplica un filtro de suavizado gaussiano y CLAHE a una imagen y devuelve la imagen procesada y sus histogramas.\n",
    "    \n",
    "    Args:\n",
    "    - image_path: Ruta de la imagen de entrada.\n",
    "    - clip_limit: Parámetro de contraste para CLAHE.\n",
    "    - tile_grid_size: Tamaño de las regiones para CLAHE.\n",
    "    - kernel_size: Tamaño del kernel para el filtro gaussiano.\n",
    "    \n",
    "    Returns:\n",
    "    - processed_img: Imagen procesada.\n",
    "    \"\"\"\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Aplicar filtro de suavizado gaussiano\n",
    "    blurred_img = cv2.GaussianBlur(img, kernel_size, 0)\n",
    "    \n",
    "    # Convertir a Lab para aplicar CLAHE\n",
    "    lab = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2Lab)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Aplicar CLAHE al canal L\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Reconstruir la imagen Lab y convertir a BGR\n",
    "    lab = cv2.merge((cl, a, b))\n",
    "    processed_img = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)\n",
    "    \n",
    "    return processed_img\n",
    "\n",
    "\n",
    "def display_images_and_histograms(df, path_column='path', clip_limit=2.0, tile_grid_size=(8, 8), kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Procesa un conjunto de imágenes desde un DataFrame, muestra las imágenes y sus histogramas.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame con las rutas de las imágenes.\n",
    "    - path_column: Nombre de la columna en el DataFrame que contiene las rutas de las imágenes.\n",
    "    - clip_limit: Parámetro de contraste para CLAHE.\n",
    "    - tile_grid_size: Tamaño de las regiones para CLAHE.\n",
    "    - kernel_size: Tamaño del kernel para el filtro gaussiano.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        \n",
    "        # Leer la imagen original\n",
    "        original_img = cv2.imread(image_path)\n",
    "        original_img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)  # Convertir a RGB para matplotlib\n",
    "        \n",
    "        # Procesar la imagen\n",
    "        processed_img = preprocess_image_with_histogram(\n",
    "            image_path,\n",
    "            clip_limit=clip_limit,\n",
    "            tile_grid_size=tile_grid_size,\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "        processed_img_rgb = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)  # Convertir a RGB para matplotlib\n",
    "        \n",
    "        # Calcular histogramas\n",
    "        def calculate_histogram(image, color_space='RGB'):\n",
    "            histograms = {}\n",
    "            if color_space == 'RGB':\n",
    "                channels = ['Red', 'Green', 'Blue']\n",
    "                colors = ['r', 'g', 'b']\n",
    "                for i, (channel, color) in enumerate(zip(channels, colors)):\n",
    "                    hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "                    histograms[channel] = (hist, color)\n",
    "            return histograms\n",
    "        \n",
    "        original_histograms = calculate_histogram(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "        processed_histograms = calculate_histogram(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Mostrar imágenes y histogramas\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # Imagen original\n",
    "        plt.subplot(2, 4, 1)\n",
    "        plt.imshow(original_img_rgb)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Histograma de la imagen original\n",
    "        plt.subplot(2, 4, 2)\n",
    "        for channel, (hist, color) in original_histograms.items():\n",
    "            plt.plot(hist, color=color, label=channel)\n",
    "        plt.title(\"Histograma Original\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Imagen procesada\n",
    "        plt.subplot(2, 4, 3)\n",
    "        plt.imshow(processed_img_rgb)\n",
    "        plt.title(\"Procesada (Suavizado + CLAHE)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Histograma de la imagen procesada\n",
    "        plt.subplot(2, 4, 4)\n",
    "        for channel, (hist, color) in processed_histograms.items():\n",
    "            plt.plot(hist, color=color, label=channel)\n",
    "        plt.title(\"Histograma Procesado\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_and_histograms(\n",
    "    df=muestra,\n",
    "    path_column='path',  # Cambia si tu columna tiene otro nombre.\n",
    "    clip_limit=2.0, \n",
    "    tile_grid_size=(8, 8), \n",
    "    kernel_size=(5, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica normalización y estandarizacion a la imagen original y se muestras las tres imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normaliza la imagen para que los valores de los píxeles estén en el rango [0, 1].\n",
    "    \n",
    "    Args:\n",
    "    - image: Imagen original (array de NumPy).\n",
    "    \n",
    "    Returns:\n",
    "    - normalized_img: Imagen normalizada (array de NumPy).\n",
    "    \"\"\"\n",
    "    return image / 255.0  # Escala los valores a [0, 1]\n",
    "\n",
    "def normalize_dataset(df, path_column='path'):\n",
    "    \"\"\"\n",
    "    Aplica normalización a todas las imágenes de un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame con las rutas de las imágenes.\n",
    "    - path_column: Nombre de la columna que contiene las rutas de las imágenes.\n",
    "    \n",
    "    Returns:\n",
    "    - normalized_images: Lista de imágenes normalizadas.\n",
    "    \"\"\"\n",
    "    normalized_images = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
    "        normalized_img = normalize_image(img)\n",
    "        normalized_images.append(normalized_img)\n",
    "    \n",
    "    return normalized_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_image(image):\n",
    "    \"\"\"\n",
    "    Estandariza la imagen para que tenga media 0 y desviación estándar 1.\n",
    "    \n",
    "    Args:\n",
    "    - image: Imagen original (array de NumPy).\n",
    "    \n",
    "    Returns:\n",
    "    - standardized_img: Imagen estandarizada (array de NumPy).\n",
    "    \"\"\"\n",
    "    mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "    std = np.std(image, axis=(0, 1), keepdims=True)\n",
    "    standardized_img = (image - mean) / (std + 1e-8)  # Evita divisiones por cero\n",
    "    return standardized_img\n",
    "\n",
    "def standardize_dataset(df, path_column='path'):\n",
    "    \"\"\"\n",
    "    Aplica estandarización a todas las imágenes de un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame con las rutas de las imágenes.\n",
    "    - path_column: Nombre de la columna que contiene las rutas de las imágenes.\n",
    "    \n",
    "    Returns:\n",
    "    - standardized_images: Lista de imágenes estandarizadas.\n",
    "    \"\"\"\n",
    "    standardized_images = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
    "        standardized_img = standardize_image(img)\n",
    "        standardized_images.append(standardized_img)\n",
    "    \n",
    "    return standardized_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images = normalize_dataset(df=muestra, path_column='path')\n",
    "print(f\"Total de imágenes normalizadas: {len(normalized_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_images = standardize_dataset(df=muestra, path_column='path')\n",
    "print(f\"Total de imágenes estandarizadas: {len(standardized_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def display_normalized_and_standardized(df, path_column='path'):\n",
    "    \"\"\"\n",
    "    Muestra imágenes originales, normalizadas y estandarizadas lado a lado.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame con las rutas de las imágenes.\n",
    "    - path_column: Nombre de la columna que contiene las rutas de las imágenes.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        \n",
    "        # Leer la imagen original\n",
    "        original_img = cv2.imread(image_path)\n",
    "        original_img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)  # Convertir a RGB para matplotlib\n",
    "        \n",
    "        # Normalización\n",
    "        normalized_img = original_img_rgb / 255.0\n",
    "        \n",
    "        # Estandarización\n",
    "        mean = np.mean(original_img_rgb, axis=(0, 1), keepdims=True)\n",
    "        std = np.std(original_img_rgb, axis=(0, 1), keepdims=True)\n",
    "        standardized_img = (original_img_rgb - mean) / (std + 1e-8)\n",
    "        standardized_img = np.clip((standardized_img - standardized_img.min()) / (standardized_img.max() - standardized_img.min()), 0, 1)  # Reescala para visualización\n",
    "        \n",
    "        # Mostrar las imágenes\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Imagen original\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(original_img_rgb)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Imagen normalizada\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(normalized_img)\n",
    "        plt.title(\"Normalizada (0 a 1)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Imagen estandarizada\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(standardized_img)\n",
    "        plt.title(\"Estandarizada (Media=0, Var=1)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_normalized_and_standardized(df=muestra, path_column='path')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una comparación de la imagen procesada (suavizada y CLAHE), la normalizada y la estandarizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, clip_limit=2.0, tile_grid_size=(8, 8), kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Aplica suavizado Gaussiano y CLAHE a una imagen.\n",
    "    \n",
    "    Args:\n",
    "    - image_path: Ruta de la imagen original.\n",
    "    - clip_limit: Parámetro de contraste para CLAHE.\n",
    "    - tile_grid_size: Tamaño de las regiones para CLAHE.\n",
    "    - kernel_size: Tamaño del kernel para el filtro Gaussiano.\n",
    "    \n",
    "    Returns:\n",
    "    - processed_img: Imagen procesada.\n",
    "    \"\"\"\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Aplicar filtro de suavizado gaussiano\n",
    "    blurred_img = cv2.GaussianBlur(img, kernel_size, 0)\n",
    "    \n",
    "    # Convertir a Lab para aplicar CLAHE\n",
    "    lab = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2Lab)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Aplicar CLAHE al canal L\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Reconstruir la imagen Lab y convertir a BGR\n",
    "    lab = cv2.merge((cl, a, b))\n",
    "    processed_img = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)\n",
    "    \n",
    "    return processed_img\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normaliza una imagen para que los valores estén en el rango [0, 1].\n",
    "    \n",
    "    Args:\n",
    "    - image: Imagen procesada (array de NumPy).\n",
    "    \n",
    "    Returns:\n",
    "    - normalized_img: Imagen normalizada (array de NumPy).\n",
    "    \"\"\"\n",
    "    return image / 255.0  # Escala los valores a [0, 1]\n",
    "\n",
    "\n",
    "def standardize_image(image):\n",
    "    \"\"\"\n",
    "    Estandariza una imagen para que tenga media 0 y desviación estándar 1.\n",
    "    \n",
    "    Args:\n",
    "    - image: Imagen procesada (array de NumPy).\n",
    "    \n",
    "    Returns:\n",
    "    - standardized_img: Imagen estandarizada (array de NumPy).\n",
    "    \"\"\"\n",
    "    mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "    std = np.std(image, axis=(0, 1), keepdims=True)\n",
    "    standardized_img = (image - mean) / (std + 1e-8)  # Evitar divisiones por cero\n",
    "    return standardized_img\n",
    "\n",
    "\n",
    "def process_and_display_images(df, path_column='path', clip_limit=2.0, tile_grid_size=(8, 8), kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Aplica suavizado y CLAHE, luego normaliza y estandariza las imágenes, y las muestra en pantalla.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame con las rutas de las imágenes.\n",
    "    - path_column: Nombre de la columna que contiene las rutas de las imágenes.\n",
    "    - clip_limit: Parámetro de contraste para CLAHE.\n",
    "    - tile_grid_size: Tamaño de las regiones para CLAHE.\n",
    "    - kernel_size: Tamaño del kernel para el filtro Gaussiano.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        \n",
    "        # Procesar la imagen (suavizado + CLAHE)\n",
    "        processed_img = preprocess_image(\n",
    "            image_path,\n",
    "            clip_limit=clip_limit,\n",
    "            tile_grid_size=tile_grid_size,\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "        processed_img_rgb = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)  # Convertir a RGB para matplotlib\n",
    "        \n",
    "        # Normalizar la imagen procesada\n",
    "        normalized_img = normalize_image(processed_img_rgb)\n",
    "        \n",
    "        # Estandarizar la imagen procesada\n",
    "        standardized_img = standardize_image(processed_img_rgb)\n",
    "        standardized_img = np.clip((standardized_img - standardized_img.min()) / (standardized_img.max() - standardized_img.min()), 0, 1)  # Reescala para visualización\n",
    "        \n",
    "        # Mostrar las imágenes\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        \n",
    "        # Imagen procesada\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(processed_img_rgb)\n",
    "        plt.title(\"Procesada (Suavizado + CLAHE)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Imagen normalizada\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(normalized_img)\n",
    "        plt.title(\"Normalizada (0 a 1)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Imagen estandarizada\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(standardized_img)\n",
    "        plt.title(\"Estandarizada (Media=0, Var=1)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_display_images(\n",
    "    df=muestra,\n",
    "    path_column='path',  # Cambia si tu columna tiene otro nombre.\n",
    "    clip_limit=2.0, \n",
    "    tile_grid_size=(8, 8), \n",
    "    kernel_size=(5, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizan varias transformaciones no lineales en las imágenes, todas se muestran a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    image = image.astype(np.float32)\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image.astype(np.uint8), table)\n",
    "\n",
    "def apply_gamma_to_muestra(df, path_column='path', gamma=1.0):\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gamma_img = adjust_gamma(img, gamma=gamma)\n",
    "        gamma_img_rgb = cv2.cvtColor(gamma_img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(gamma_img_rgb)\n",
    "        plt.title(f\"Transformada Gamma (Gamma={gamma})\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_log_transform(image):\n",
    "    image = image.astype(np.float32)\n",
    "    c = 255 / np.log(1 + np.max(image))\n",
    "    log_image = c * np.log(1 + image)\n",
    "    return np.uint8(log_image)\n",
    "\n",
    "def apply_log_to_muestra(df, path_column='path'):\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        log_img = apply_log_transform(img)\n",
    "        log_img_rgb = cv2.cvtColor(log_img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(log_img_rgb)\n",
    "        plt.title(\"Transformada Logarítmica\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_exponential_transform(image):\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    exp_image = np.exp(image) - 1\n",
    "    exp_image = np.clip(exp_image / np.max(exp_image), 0, 1) * 255\n",
    "    return np.uint8(exp_image)\n",
    "\n",
    "def apply_exponential_to_muestra(df, path_column='path'):\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        exp_img = apply_exponential_transform(img)\n",
    "        exp_img_rgb = cv2.cvtColor(exp_img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(exp_img_rgb)\n",
    "        plt.title(\"Transformada Exponencial\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sigmoid_transform(image, gain=5, cutoff=128):\n",
    "    image = image.astype(np.float32)\n",
    "    sigmoid_image = 1 / (1 + np.exp(-gain * (image - cutoff) / 255.0))\n",
    "    return (sigmoid_image * 255).astype(np.uint8)\n",
    "\n",
    "def apply_sigmoid_to_muestra(df, path_column='path', gain=5, cutoff=128):\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        sigmoid_img = apply_sigmoid_transform(img, gain=gain, cutoff=cutoff)\n",
    "        sigmoid_img_rgb = cv2.cvtColor(sigmoid_img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(sigmoid_img_rgb)\n",
    "        plt.title(f\"Transformada Sigmoidal (Gain={gain}, Cutoff={cutoff})\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bilateral_filter(image, diameter=15, sigma_color=75, sigma_space=75):\n",
    "    return cv2.bilateralFilter(image, diameter, sigma_color, sigma_space)\n",
    "\n",
    "def apply_bilateral_to_muestra(df, path_column='path', diameter=15, sigma_color=75, sigma_space=75):\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        bilateral_img = apply_bilateral_filter(img, diameter, sigma_color, sigma_space)\n",
    "        bilateral_img_rgb = cv2.cvtColor(bilateral_img, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(bilateral_img_rgb)\n",
    "        plt.title(\"Filtro Bilateral\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_adaptive_threshold(image, method=cv2.ADAPTIVE_THRESH_GAUSSIAN_C):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.adaptiveThreshold(gray, 255, method, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "def apply_adaptive_threshold_to_muestra(df, path_column='path', method=cv2.ADAPTIVE_THRESH_GAUSSIAN_C):\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[path_column]\n",
    "        img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        thresh_img = apply_adaptive_threshold(img, method=method)\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(thresh_img, cmap='gray')\n",
    "        plt.title(\"Umbral Adaptativo\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gamma_to_muestra(muestra, path_column='path', gamma=1.2)\n",
    "apply_log_to_muestra(muestra, path_column='path')\n",
    "apply_exponential_to_muestra(muestra, path_column='path')\n",
    "apply_sigmoid_to_muestra(muestra, path_column='path', gain=5, cutoff=128)\n",
    "apply_bilateral_to_muestra(muestra, path_column='path')\n",
    "apply_adaptive_threshold_to_muestra(muestra, path_column='path')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operaciones morfologicas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
